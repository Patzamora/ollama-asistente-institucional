# ollama-asistente-institucional
Proyecto uso Ollama
# ðŸ§  Asistente Inteligente con Ollama

Este proyecto implementa un asistente institucional local usando modelos de lenguaje grande (LLM) desplegados con [Ollama](https://ollama.com).

## ðŸ’¡ PropÃ³sito
Brindar respuestas claras y accesibles sobre normativas a los ciudadanos, simulando un asistente para el Ministerio de Hacienda de Costa Rica.

## ðŸš€ Requisitos
- Python 3.8+
- Docker y Ollama instalados y funcionando localmente

## ðŸ”§ InstalaciÃ³n
```bash
pip install -r requirements.txt
```

## â–¶ Uso
Ejecutar la app principal desde consola:
```bash
python app.py
```

## ðŸ›  Estructura
- `prompts/`: Contiene el prompt base del modelo
- `utils/`: CÃ³digo auxiliar para llamar a Ollama
- `respuestas/`: Ejemplos documentados de uso
- `docs/`: DiseÃ±o del sistema y arquitectura
